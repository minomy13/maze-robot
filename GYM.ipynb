{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3573b3",
   "metadata": {},
   "source": [
    "# Maze Robot Code\n",
    "Testing Q-Learning Code with Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8316c5",
   "metadata": {},
   "source": [
    "### Imports\n",
    "|Package|Usage|Link|\n",
    "|-|-|-|\n",
    "|gym|Software for testing AI without real Hardware.|https://gym.openai.com|\n",
    "|numpy|The fundamental package for scientific computing with Python|https://numpy.org|\n",
    "|random|Generates random numbers| |\n",
    "|clear_output|Cleares console output| | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becafcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b474da2",
   "metadata": {},
   "source": [
    "### Initializing Variables\n",
    "|Name|Usage|\n",
    "|---|---|\n",
    "|environment|Envireonment for testing the AI provided by GYM|\n",
    "|hyperparam|Provides the parameters used by the Q-Learning formula|\n",
    "|res|Holds the responses from the environment|\n",
    "|epoch_array|Array holding all epochs|\n",
    "|penalty_array|Array holding all penaltys|\n",
    "|q_table|See \"Q-Table Subheading|\n",
    "\n",
    "#### Q-Table\n",
    "`np.zeros` = Table; `[Amount of Observations, Amount of possible options (Drop, Pick, L, R, U, D)]` = Columns and Rows of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be056b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "class hyperparam:\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.6\n",
    "        self.epsilon = 0.1\n",
    "\n",
    "class res:\n",
    "    def __init__(self, action, state, reward, done, info):\n",
    "        self.action = action\n",
    "        self.state = state\n",
    "        self.reward = reward\n",
    "        self.done = done\n",
    "        self.info = info\n",
    "\n",
    "epoch_array = []\n",
    "penatlty_array = []\n",
    "\n",
    "q_table = np.zeros([environment.obervation_space.n, environment.action_space.n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3814e616",
   "metadata": {},
   "source": [
    "### Training Algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 100001):\n",
    "    state = environment.reset()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
